<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="来自贫穷小山村，但我想回去">
    <meta name="keyword" content="">
    <meta name="theme-color" content="#600090">
    <meta name="msapplication-navbutton-color" content="#600090">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="#600090">
    <link rel="shortcut icon" href="https://cdn4.iconfinder.com/data/icons/ionicons/512/icon-person-128.png">
    <link rel="alternate" type="application/atom+xml" title="生死看淡，不服就干" href="/atom.xml">
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css">
    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.css">
    <title>
        
        python爬虫初涉｜undefined
        
    </title>

    <link rel="canonical" href="http://yoursite.com/2018/02/06/python抓妹子/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/blog-style.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">
</head>

<style>

    header.intro-header {
        background-image: url('')
    }
</style>
<!-- hack iOS CSS :active style -->
<body ontouchstart="" class="animated fadeIn">
<!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top " id="nav-top" data-ispost = "true" data-istags="false
" data-ishome = "false" >
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand animated pulse" href="/">
                <span class="brand-logo">
                    生死看淡，不服就干
                </span>
                's Blog
            </a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <!-- /.navbar-collapse -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
					
                    
					
					
                </ul>
            </div>
        </div>
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
//    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>

<!-- Main Content -->

<!--only post-->


<img class="wechat-title-img"
     src="">


<style>
    
    header.intro-header {
        background-image: url('')
    }

    
</style>

<header class="intro-header">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <div class="post-heading">
                    <h1>python爬虫初涉</h1>
                    
                    <span class="meta">
                         作者 塑料葫芦娃
                        <span>
                          日期 2018-02-06
                         </span>
                    </span>
                    <div class="tags text-center">
                        
                        <a class="tag" href="/tags/#技术"
                           title="技术">技术</a>
                        
                        <a class="tag" href="/tags/#python"
                           title="python">python</a>
                        
                        <a class="tag" href="/tags/#爬虫"
                           title="爬虫">爬虫</a>
                        
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="post-title-haojen">
        <span>
            python爬虫初涉
        </span>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">
            <!-- Post Container -->
            <div class="col-lg-8 col-lg-offset-1 col-sm-9 post-container">
                <p><img src="http://op0dvu7tu.bkt.clouddn.com/helo004.jpg" alt="enter image description here"></p>
<h3 id="文章简介"><a href="#文章简介" class="headerlink" title="文章简介"></a>文章简介</h3><p><strong>本文将介绍如何使用python对www.mzitu.com中所有的图片的爬取以及存储到本地最后我们会得到如下图1所示</strong></p>
<p><img src="http://op0dvu7tu.bkt.clouddn.com/%E4%BA%91%E4%B9%8B%E5%AE%B6%E5%9B%BE%E7%89%8720180206142745.png" alt="enter image description here"></p>
<p>是不是很心动，接下来就让我们开始python爬虫之旅，本期内容将会从单线程使用到多线程，从自己写python到使用scrapy包，以及分布式redis的使用，当然这些都是后话了，当前我们的目标是要爬去这个网站上的美图。</p>
<h3 id="环境介绍"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍</h3><p>废话少说接下来就是我们的基础环境部分<br><strong>1.Python – 3.6.1</strong>（这个版本其实要区别的就是python2和python3啦，我使用的python3）</p>
<p><strong>2.Requests</strong> （看名字就知道这个是用来进行网络请求用的，这里的request是rllib包中的，之后我们要学的scrapy中也有自己想要的request，到时候两个不要搞混了）</p>
<p><strong>3.beautifulsoup</strong> （当然数据获取到了之后，我们要对数据进行提取，解析就是通过beautifulsoup来进行，当然我们自己也可通过正则表达式来对数据进行过滤，如果你的正则水平不错的情况下） </p>
<p><strong>4.LXML</strong> 一个HTML解析包 用于辅助beautifulsoup解析网页  </p>
<hr>
<p><strong>上面的模块需要 单独安装，下面几个就不用啦。</strong></p>
<hr>
<p><strong>5.OS 系统内置模块</strong> （这个玩意是系统内置的，在本文中我们通过它来将图片存储在本地）</p>
<p><strong>6.PyCharm</strong>   一个草鸡好用的PythonIDE工具 、真滴。</p>
<h3 id="模块的安装"><a href="#模块的安装" class="headerlink" title="模块的安装"></a>模块的安装</h3><p>再使用pip指令之前我们需要安装python。（如果我们安装python时选择<strong>不将</strong>python写入环境变量的话，那么我们还需要将“文件夹\python36”和“文件夹\python36\Scripts”写入path中，这样我们才能在控制台中使用python和pip指令）</p>
<p><strong>接下来就用指令安装模块</strong></p>
<pre><code>pip install requests   
pip install beautifulsoup4  
pip install lxml
</code></pre><p>大致结果就如下图所示<br><img src="http://op0dvu7tu.bkt.clouddn.com/%E4%BA%91%E4%B9%8B%E5%AE%B6%E5%9B%BE%E7%89%8720180206150606.png" alt="enter image description here"></p>
<p>当python + 3个模块 + PyCharm安装完成之后我们就可以开始我们本次抓取的代码编写了。</p>
<h3 id="爬虫编写"><a href="#爬虫编写" class="headerlink" title="爬虫编写"></a>爬虫编写</h3><p><strong>首先我们先整理一下爬图片的步骤：</strong></p>
<p>1.我们需要一个目标网站（www.mzitu.com）<br>2.我们需要从一个网页中找出接下来要去的网页的链接地址，通过beautifulsoup来获取<br>3.获取网页中的图片地址<br>4.下载图片到本地</p>
<p><strong>步骤1：</strong><br>www.mzitu.com网站的截图如下，这里选择了www.mzitu.com/all作为起始网页，因为在该网页中包含了网站中所有图片组图的链接链接地址<br><img src="http://op0dvu7tu.bkt.clouddn.com/%E4%BA%91%E4%B9%8B%E5%AE%B6%E5%9B%BE%E7%89%8720180206160047.png" alt="enter image description here"></p>
<p><strong>步骤2：</strong><br>推荐使用chrome浏览器来进行网页源码的查看<br><img src="http://op0dvu7tu.bkt.clouddn.com/%E4%BA%91%E4%B9%8B%E5%AE%B6%E5%9B%BE%E7%89%8720180206160522.png" alt="enter image description here"></p>
<p>通过观察我们可以发现接下来的链接地址在所在的<strong>href</strong>是被<strong>div class=all</strong>所包含着的，所有我们可以使用这一点来找到所有的url地址</p>
<p><strong>步骤3：</strong><br>接下来我们就进入到某个链接里面去看图了<br><img src="http://op0dvu7tu.bkt.clouddn.com/%E4%BA%91%E4%B9%8B%E5%AE%B6%E5%9B%BE%E7%89%8720180206161232.png" alt="enter image description here"><br>相应图片的地址被包含在<strong>div class=’main-image’</strong>中</p>
<p>注意着个有一套图（一般她们拍写真都有很多张的），所以呢我们就看下接下来的这张图<br><img src="http://op0dvu7tu.bkt.clouddn.com/%E4%BA%91%E4%B9%8B%E5%AE%B6%E5%9B%BE%E7%89%8720180206161358.png" alt="enter image description here"><br>着张图里的<strong>href</strong>就是套图里其他图片所在网页的地址了，有了这个我们就可以获取接下来的图片了，其中通过观察可以发现<strong>href</strong>被包在<strong>div class=‘pagenavi’</strong>中</p>
<p><strong>步骤4：</strong><br><strong>开始代码编写</strong></p>
<p>我们需要在代码中引入相应的模块</p>
<pre><code>import requests
from bs4 import BeautifulSoup
import os
</code></pre><p>获取起始网页内容</p>
<pre><code>html = self.request(url)
</code></pre><p>这里的request是下面的这个方法</p>
<pre><code>def request(self, url):  ##这个函数获取网页的response 然后返回
    headers = {
    &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;}
    content = requests.get(url, headers=headers)

    return content
</code></pre><p>获取步骤1中内容（也就是所有套图的地址），并进一步发送请求获取到套图首张图片所在网页</p>
<pre><code>all_a = BeautifulSoup(html.text, &apos;lxml&apos;).find(&apos;div&apos;, class_=&apos;all&apos;).find_all(&apos;a&apos;)
for a in all_a:       
    title = a.get_text() #取出a标签的文本       
    href = a[&apos;href&apos;] #取出a标签的href 属性，也就是套图地址
    self.html(href, &quot;e:\\pic\\&quot; + path)
</code></pre><p>相应的html方法</p>
<pre><code>def html(self, href, path):  ##这个函数是处理套图地址获得图片的页面地址
    html = self.request(href)
    helo = BeautifulSoup(html.text, &apos;lxml&apos;).find_all(&apos;span&apos;)
    if len(helo) &lt; 10:
        return
    max_span = helo[10].get_text()
    for page in range(1, int(max_span) + 1):
        page_url = href + &apos;/&apos; + str(page)
        self.img(page_url, path)  ##调用img函数
</code></pre><p>上面的html方法中的后半截是执行了步骤3中的后半部分，也就是遍历了套图中其他图片所在的网页，相应的img方法如下</p>
<pre><code>def img(self, page_url, path):  ##这个函数处理图片页面地址获得图片的实际地址
    img_html = self.request(page_url)
    helo = BeautifulSoup(img_html.text, &apos;lxml&apos;).find(&apos;div&apos;, class_=&apos;main-image&apos;)
    if helo is not None:
        helo1 = helo.find(&apos;img&apos;)
        if helo1 is not None:
            # do some thing you need
            img_url = helo1[&apos;src&apos;]
            self.saveImg(img_url, path)

def saveImg(self, url, path):
    getHeaders = {
        &apos;Host&apos;: &apos;i.meizitu.net&apos;,
        &apos;Connection&apos;: &apos;Keep-Alive&apos;,
        &apos;Accept&apos;: &apos;image/webp,image/apng,image/*,*/*;q=0.8&apos;,
        &apos;Upgrade-Insecure-Requests&apos;: &apos;1&apos;,
        &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36&apos;,
        &apos;Referer&apos;: &apos;http://www.mzitu.com/&apos;,
        &apos;Accept-Encoding&apos;: &apos;gzip, deflate&apos;,
        &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;
    }
    response = requests.get(url, headers=getHeaders)

    if (response.status_code == 404):  # 若404错误，递归get，尝试非重定向方式获取
        response = requests.get(url, headers=getHeaders, allow_redirects=False)
        if (response.status_code == 302):  # 302表示访问对象已被移动到新位置，但仍按照原地址进行访问（造成404错误）。
            name = url[-9:-4]
            redirectUrl = response.headers[&apos;location&apos;]  # 因此需在响应头文件中获取重定向后地址
            response = requests.get(redirectUrl)
            fp = open(name + &quot;.jpg&quot;, &apos;ab&apos;)
            fp.write(response.content)
            fp.close()
    else:
        os.chdir(path)
        name = url[-9:-4]
        fp = open(name + &quot;.jpg&quot;, &apos;ab&apos;)
        fp.write(response.content)
        fp.close()
        self.picNum = self.picNum + 1
        print(self.picNum)
</code></pre><p>方法saveImg执行了步骤4，也就是将图片保存在了本地。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本片文字是在之前微信上看到的一篇文章改写的，当时照着那篇文字将代码写了一遍之后发现，保存在本地的图片都被篡改了，也就是被防盗链了，而后就只能修改request中的一些参数来确保准确性。在上面这些完成后，发现对爬虫有了一点的了解之后想着是不是可以使用多线程的方式来爬去，就又看了多线程的写法，下面贴出多线程的代码，这里使用的线程池。</p>
<p><strong>多线程代码</strong></p>
<pre><code>import requests
from bs4 import BeautifulSoup
import os
import threading
import threadpool


class mzitu():
    num = 0
    picNum = 0

    def all_url(self, url):
        self.cv = threading.Condition()
        html = self.request(url)  ##调用request函数把套图地址传进去会返回给我们一个response
        all_a = BeautifulSoup(html.text, &apos;lxml&apos;).find(&apos;div&apos;, class_=&apos;all&apos;).find_all(&apos;a&apos;)

        task_pool = threadpool.ThreadPool(50)
        requests = threadpool.makeRequests(self.nice, all_a)
        for req in requests:
            task_pool.putRequest(req)
        task_pool.wait()

    def nice(self, a):
        title = a.get_text()
        path = str(title).replace(&quot;?&quot;, &apos;_&apos;)  ##我注意到有个标题带有 ？  这个符号Windows系统是不能创建文件夹的所以要替换掉
        if self.mkdir(path):  ##调用mkdir函数创建文件夹！这儿path代表的是标题title哦！！！！！不要糊涂了哦！
            os.chdir(&quot;e:\\pic\\&quot; + path)  ##切换到目录
            href = a[&apos;href&apos;]
            self.html(href, &quot;e:\\pic\\&quot; + path)  ##调用html函数把href参数传递过去！href是啥还记的吧？ 就是套图的地址哦！！不要迷糊了哦！

    def html(self, href, path):  ##这个函数是处理套图地址获得图片的页面地址
        html = self.request(href)
        helo = BeautifulSoup(html.text, &apos;lxml&apos;).find_all(&apos;span&apos;)
        if len(helo) &lt; 10:
            return
        max_span = helo[10].get_text()
        for page in range(1, int(max_span) + 1):
            page_url = href + &apos;/&apos; + str(page)
            self.img(page_url, path)  ##调用img函数

    def img(self, page_url, path):  ##这个函数处理图片页面地址获得图片的实际地址
        img_html = self.request(page_url)
        helo = BeautifulSoup(img_html.text, &apos;lxml&apos;).find(&apos;div&apos;, class_=&apos;main-image&apos;)
        if helo is not None:
            helo1 = helo.find(&apos;img&apos;)
            if helo1 is not None:
                # do some thing you need
                img_url = helo1[&apos;src&apos;]
                self.saveImg(img_url, path)

    def mkdir(self, path):  ##这个函数创建文件夹
        path = path.strip()
        if path.__contains__(&quot;妲己&quot;):
            return False
        isExists = os.path.exists(os.path.join(&quot;e:\\pic\\&quot;, path))
        if not isExists:
            os.makedirs(os.path.join(&quot;e:\\pic\\&quot;, path))
            return True
        else:
            return False

    def request(self, url):  ##这个函数获取网页的response 然后返回
        headers = {
            &apos;User-Agent&apos;: &quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;}
        content = requests.get(url, headers=headers)

        return content

    def saveImg(self, url, path):
        getHeaders = {
            &apos;Host&apos;: &apos;i.meizitu.net&apos;,
            &apos;Connection&apos;: &apos;Keep-Alive&apos;,
            &apos;Accept&apos;: &apos;image/webp,image/apng,image/*,*/*;q=0.8&apos;,
            &apos;Upgrade-Insecure-Requests&apos;: &apos;1&apos;,
            &apos;User-Agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36&apos;,
            &apos;Referer&apos;: &apos;http://www.mzitu.com/&apos;,
            &apos;Accept-Encoding&apos;: &apos;gzip, deflate&apos;,
            &apos;Accept-Language&apos;: &apos;zh-CN,zh;q=0.9&apos;
        }

        response = requests.get(url, headers=getHeaders)
        if (response.status_code == 404):  # 若404错误，递归get，尝试非重定向方式获取
            response = requests.get(url, headers=getHeaders, allow_redirects=False)
            if (response.status_code == 302):  # 302表示访问对象已被移动到新位置，但仍按照原地址进行访问（造成404错误）。
                name = url[-9:-4]
                redirectUrl = response.headers[&apos;location&apos;]  # 因此需在响应头文件中获取重定向后地址
                response = requests.get(redirectUrl)
                fp = open(name + &quot;.jpg&quot;, &apos;ab&apos;)
                fp.write(response.content)
                fp.close()
        else:
            os.chdir(path)
            name = url[-9:-4]
            fp = open(name + &quot;.jpg&quot;, &apos;ab&apos;)
            fp.write(response.content)
            fp.close()
            self.picNum = self.picNum + 1
            print(self.picNum)

Mzitu = mzitu()  ##实例化
Mzitu.all_url(&apos;http://www.mzitu.com/all&apos;)  ##给函数all_url传入参数  你可以当作启动爬虫（就是入口）
</code></pre>
                <hr>
                

                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/2018/02/06/python爬虫scrapy的使用/" data-toggle="tooltip" data-placement="top"
                           title="python爬虫scrapy的使用">&larr; Previous Post</a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2016/06/01/Dagger2/" data-toggle="tooltip" data-placement="top"
                           title="Dagger2全面解析">Next Post &rarr;</a>
                    </li>
                    
                </ul>

                

                


                <!--加入新的评论系统-->
                
            </div>

            <div class="hidden-xs col-sm-3 toc-col">
                <div class="toc-wrap">
                    <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#文章简介"><span class="toc-text">文章简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#环境介绍"><span class="toc-text">环境介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模块的安装"><span class="toc-text">模块的安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#爬虫编写"><span class="toc-text">爬虫编写</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#总结"><span class="toc-text">总结</span></a></li></ol>
                </div>
            </div>
        </div>

        <div class="row">
            <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                

                <!-- Friends Blog -->
                
            </div>
        </div>

    </div>
</article>







<!-- Footer -->
<!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 text-center">
                <br>
                <ul class="list-inline text-center">
                
                
                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; 生死看淡，不服就干 2018
                    <br>
                    <span id="busuanzi_container_site_pv" style="font-size: 12px;">PV: <span id="busuanzi_value_site_pv"></span> Times</span>
                    <br>
                    Theme by <a href="https://haojen.github.io/">Haojen Ma</a>
                </p>

            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/blog.js"></script>

<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://yoursite.com/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>

<!-- Google Analytics -->



<!-- Baidu Tongji -->


<!-- swiftype -->
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','','2.0.0');
</script>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<!--wechat title img-->
<img class="wechat-title-img" src="">
</body>

</html>
